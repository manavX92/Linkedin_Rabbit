#!/usr/bin/env python3
"""
LinkedIn Rabbit - Command Line Interface

This script provides a command-line interface for the LinkedIn Rabbit scraper.
"""

import os
import sys
import argparse
import time
from datetime import datetime
from fpdf import FPDF
from .linkedin_rabbit import scrape_linkedin_posts, read_input_file
from .static.logo import print_logo

def create_pdf(text_file):
    """Create a PDF file from the text file."""
    try:
        # Read the text file
        with open(text_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # Extract profile name from the filename
        profile_name = os.path.basename(text_file).split('_linkedin_posts_')[0]
        
        # Parse the text file
        lines = content.split('\n')
        posts_data = []
        current_post = None
        
        for line in lines:
            if line.startswith('Post #'):
                if current_post:
                    posts_data.append(current_post)
                current_post = {'content': ''}
            elif current_post:
                if line.startswith('Date:'):
                    current_post['date'] = line[5:].strip()
                elif line.startswith('Engagement:'):
                    engagement_text = line[11:].strip()
                    likes = comments = shares = '0'
                    
                    import re
                    likes_match = re.search(r'(\d+) likes', engagement_text)
                    if likes_match:
                        likes = likes_match.group(1)
                    
                    comments_match = re.search(r'(\d+) comments', engagement_text)
                    if comments_match:
                        comments = comments_match.group(1)
                    
                    shares_match = re.search(r'(\d+) shares', engagement_text)
                    if shares_match:
                        shares = shares_match.group(1)
                    
                    current_post['engagement'] = {
                        'likes': likes,
                        'comments': comments,
                        'shares': shares
                    }
                elif not line.startswith('=') and not line.startswith('-') and not line.startswith('LinkedIn Posts for:') and not line.startswith('Extracted on:') and not line.startswith('Number of posts:'):
                    current_post['content'] += line + '\n'
        
        # Add the last post
        if current_post:
            posts_data.append(current_post)
        
        # Create PDF
        pdf = FPDF()
        pdf.add_page()
        
        # Set font
        pdf.set_font("Arial", "B", 16)
        
        # Title
        pdf.cell(0, 10, f"LinkedIn Posts for: {profile_name}", 0, 1, "C")
        pdf.set_font("Arial", "", 12)
        pdf.cell(0, 10, f"Extracted on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}", 0, 1, "C")
        pdf.cell(0, 10, f"Number of posts: {len(posts_data)}", 0, 1, "C")
        pdf.line(10, pdf.get_y(), 200, pdf.get_y())
        pdf.ln(5)
        
        # Add posts
        for idx, post in enumerate(posts_data, 1):
            pdf.set_font("Arial", "B", 14)
            pdf.cell(0, 10, f"Post #{idx}", 0, 1)
            
            pdf.set_font("Arial", "I", 12)
            pdf.cell(0, 10, f"Date: {post['date']}", 0, 1)
            
            # Format engagement data
            engagement = post['engagement']
            engagement_str = f"{engagement.get('likes', '0')} likes, {engagement.get('comments', '0')} comments, {engagement.get('shares', '0')} shares"
            pdf.cell(0, 10, f"Engagement: {engagement_str}", 0, 1)
            
            pdf.ln(5)
            pdf.set_font("Arial", "", 12)
            
            # Handle multi-line content
            content_lines = post['content'].split('\n')
            for line in content_lines:
                # Split long lines
                while len(line) > 80:
                    pdf.multi_cell(0, 10, line[:80])
                    line = line[80:]
                pdf.multi_cell(0, 10, line)
            
            pdf.ln(5)
            pdf.line(10, pdf.get_y(), 200, pdf.get_y())
            pdf.ln(5)
            
            # Add a new page if needed
            if idx < len(posts_data) and pdf.get_y() > 250:
                pdf.add_page()
        
        # Footer
        pdf.set_y(-15)
        pdf.set_font("Arial", "I", 8)
        pdf.cell(0, 10, "Generated by LinkedIn Rabbit | @tensor._.boy", 0, 0, "C")
        
        # Save PDF
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        pdf_filename = f"output/{profile_name}_linkedin_posts_{timestamp}.pdf"
        pdf.output(pdf_filename)
        
        return pdf_filename
    except Exception as e:
        print(f"Error creating PDF: {e}")
        return None

def parse_arguments():
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(description='LinkedIn Rabbit - LinkedIn Post Scraper')
    
    # Create a mutually exclusive group for input methods
    input_group = parser.add_mutually_exclusive_group(required=True)
    input_group.add_argument('--file', help='Path to input file (default: linkedin_input.txt)', default='linkedin_input.txt')
    input_group.add_argument('--url', help='LinkedIn profile URL')
    
    # Arguments for direct command line input
    parser.add_argument('--posts', type=int, help='Number of posts to extract')
    parser.add_argument('--username', help='LinkedIn username/email')
    parser.add_argument('--password', help='LinkedIn password')
    parser.add_argument('--headless', action='store_true', help='Run in headless mode')
    parser.add_argument('--pdf', action='store_true', help='Generate PDF output')
    
    return parser.parse_args()

def main():
    """Main function to run the CLI."""
    print_logo()
    
    args = parse_arguments()
    
    # Create output directory if it doesn't exist
    os.makedirs("output", exist_ok=True)
    
    # Determine input method
    if args.url:
        # Direct command line input
        if not args.posts or not args.username or not args.password:
            print("Error: When using --url, you must also provide --posts, --username, and --password")
            sys.exit(1)
            
        profile_url = args.url
        num_posts = args.posts
        username = args.username
        password = args.password
        headless = args.headless
    else:
        # Input file
        print(f"Reading inputs from {args.file}...")
        inputs = read_input_file(args.file)
        if not inputs:
            print(f"Failed to read inputs from {args.file}. Please check the file format.")
            sys.exit(1)
            
        profile_url = inputs['profile_url']
        num_posts = inputs['num_posts']
        username = inputs['username']
        password = inputs['password']
        headless = inputs['headless']
    
    print(f"Profile URL: {profile_url}")
    print(f"Number of posts: {num_posts}")
    print(f"Username: {username}")
    print(f"Headless mode: {'Yes' if headless else 'No'}")
    
    print("\nStarting the scraper...")
    start_time = time.time()
    
    # Run the scraper
    result_file = scrape_linkedin_posts(
        profile_url,
        num_posts,
        username,
        password,
        headless
    )
    
    end_time = time.time()
    elapsed_time = end_time - start_time
    
    if result_file:
        print(f"\nSuccess! Posts have been extracted from {profile_url}")
        print(f"Posts saved to: {result_file}")
        print(f"Time taken: {elapsed_time:.2f} seconds")
        
        # Generate PDF if requested
        if args.pdf:
            print("\nGenerating PDF...")
            pdf_file = create_pdf(result_file)
            if pdf_file:
                print(f"PDF saved to: {pdf_file}")
            else:
                print("Failed to generate PDF.")
    else:
        print("\nFailed to extract posts. Please check your inputs and try again.")
        sys.exit(1)

if __name__ == "__main__":
    main() 